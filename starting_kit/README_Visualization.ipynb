{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1>Solve Xporters traffic volume problem</h1>\n",
    "<em><font size=\"-2\">Organisers : Alexis de Russ&eacute;, Florian Bertelli, Gaspard Donada--Vidal, Ghassen Chaabane, Moez Ezzeddine, Ziheng Li</font></em>\n",
    "<hr>\n",
    "<figure><img src=\"logo.jpg\", width=300, border=20 style=\"float:left;margin:5px\"></figure>\n",
    "<p><br>This code was tested with Python 3.7 |Anaconda custom (64-bit)| (Oct 01 2019, 11:07:29) (<a href=\"https://anaconda.org/\">https://anaconda.org/</a>).<br>\n",
    "<font size=\"-3\">ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</font></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Introduction </h2>\n",
    "    <p>\n",
    "With globalization, our world tends to be more and more connected, so this implies more and more transport. There\n",
    " are various types of transports: transports of goods, energy, information, or people.This century will be marked by a revolution in the transport of people. With the development of autonomous cars, more and more data will be collected: speed, location, population,etc. The challenge is to get value from this. As the number of cars, and particularly autonomous cars tends to grow, we'll need to deal with an increasing traffic flow to avoid huge traffic jams. Indeed, some experts pretend that autonomous vehicles will be able to reduce travelling timeup to 30%, even if the world traffic increases of 10%.\n",
    "But how is it possible to reduce travelling time and traffic jams if the number of vehicles increases ? Thanks to prediction. <br>\n",
    "        In fact, prediction will be the key to determine the fastest way to get you from your home to your work, without getting in traffic jams. Predictions may also be used to determine which transportation infrastructures to\n",
    "build.\n",
    "            <p>\n",
    "Xporters challenge is a small standard multivariable regression data set from the <a href=\"http://archive.ics.uci.edu/ml/datasets/\">UCI Machine Learning Repository</a>, formatted in the AutoML format. It uses a data set concerning the traffic volume off an highway in the USA from 2012 to 2018, the date, and some informations about the weather. The aim of this challenge is to predict the traffic volume thanks to this features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-812199fb2eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'                        \n",
    "# Change the model to a better one once you have one!\n",
    "#model_dir = '../FILES/pretty_good_sample_code_submission/'\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "# Uncomment the next lines to auto-reload libraries (this causes some problem with pickles in Python 3)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import read_as_df\n",
    "data_dir = 'input_data'       # Change this to the directory where you put the input data\n",
    "data_name = 'xporters'\n",
    "!ls $data_dir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_as_df(data_dir  + '/' + data_name)                # The data are loaded as a Pandas Data Frame\n",
    "#?? read_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.distplot(data['target'], bins=50)\n",
    "plt.title('The distribution of the traffic volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "plt.subplot(313)\n",
    "sns.boxplot('hour','target', data= data)\n",
    "plt.title('Boxplot of the traffic volume according to hour')\n",
    "\n",
    "plt.subplot(321)\n",
    "sns.boxplot('weekday','target', data= data)\n",
    "plt.title('Boxplot of the traffic volume according to the day')\n",
    "plt.subplot(322)\n",
    "sns.lineplot('weekday','target', data= data)\n",
    "plt.title(\"The distribution of the traffic volume according the day\")\n",
    "\n",
    "plt.subplot(323)\n",
    "sns.boxplot('year','target', data= data)\n",
    "plt.title('Boxplot of the traffic volume according to the year')\n",
    "plt.subplot(324)\n",
    "sns.lineplot('year','target', data= data)\n",
    "plt.title(\"The distribution of the traffic volume according years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(data.corr(), fignum=f.number)\n",
    "plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most important features according to the correlation with target')\n",
    "most_important_features = data.corr()['target'].sort_values(ascending=False)[:10]\n",
    "print (most_important_features, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(most_important_features.index)\n",
    "sns.pairplot(data,height= 5, x_vars = a , y_vars = 'target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1>Step 2: Building a predictive model</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Loading data with DataManager</h2>\n",
    "    <p>\n",
    "We reload the data with the AutoML DataManager class because this is more convenient:\n",
    "   <br>     <span style=\"color:red\"> Keep this, it illustrates how data in AutoML formal are loaded by the ingestion program </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Training a predictive model</h2>\n",
    "    <p>\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import write\n",
    "from model import model\n",
    "# Uncomment the next line to show the code of the model\n",
    "#??model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "an instance of the model (run the constructor) and attempt to reload a previously saved version from `sample_code_submission/`:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model()\n",
    "trained_model_name = model_dir + data_name\n",
    "# Uncomment the next line to re-load an already trained model\n",
    "#M = M.load()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    Train the model (unless you reloaded a trained model) and make predictions. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']\n",
    "if not(M.is_trained) : M.fit(X_train, Y_train)                     \n",
    "Y_hat_train = M.predict(D.data['X_train']) # Optional, not really needed to test on taining examples\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b> Save the trained model </b> (will be ready to reload next time around) and save the prediction results. IMPORTANT: if you save the trained model, it will be bundled with your sample code submission. Therefore your model will NOT be retrained on the challenge platform. Remove the pickle from the submission if you want the model to be retrained on the platform.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.save(trained_model_name)                 \n",
    "result_name = result_dir + data_name\n",
    "from data_io import write\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Scoring the results</h2>\n",
    "    <h3>Load the challenge metric</h3>\n",
    "    <p>\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. The function \"get_metric\" searches first for a metric having that name in my_metric.py, then in libscores.py, then in sklearn.metric.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h3> Training performance </h3>\n",
    "    <p>\n",
    "The participants normally posess target values (labels) only for training examples (except for the sample data). We compute with the `example` metric the training score, which should be zero for perfect predictions.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You can add here other scores and result visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "## Cluster Generation\n",
    "### Using sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "\n",
    "def set_plot_config():\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"poster\")\n",
    "    mpl.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "    mpl.rcParams['figure.dpi'] = 80\n",
    "    mpl.rcParams['savefig.dpi'] = 100\n",
    "    mpl.rcParams['font.size'] = 10\n",
    "    mpl.rcParams['axes.labelsize'] = 10\n",
    "    mpl.rcParams['axes.titlesize'] = 17\n",
    "    mpl.rcParams['ytick.labelsize'] = 10\n",
    "    mpl.rcParams['xtick.labelsize'] = 10\n",
    "    mpl.rcParams['legend.fontsize'] = 'large'\n",
    "    mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "set_plot_config()\n",
    "\n",
    "#Sample data\n",
    "nb_cluster = 3\n",
    "rdm_state=0\n",
    "[n_samp, n_feat] = data.shape\n",
    "X,y = make_blobs(n_samples=n_samp,n_features=n_feat,random_state=rdm_state)\n",
    "# fit on the whole data\n",
    "#training time\n",
    "t0 = time.time()\n",
    "kmeans = KMeans(n_clusters=nb_cluster,random_state=rdm_state).fit(X)\n",
    "t_batch = time.time() - t0\n",
    "\n",
    "#Plot results\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = ['#4EACC5', '#FF9C34', '#4E9A06']\n",
    "centers = kmeans.cluster_centers_\n",
    "clusters = len(centers)\n",
    "#Compute minimum distances between one point and a set of points.\n",
    "kmeans_labels = pairwise_distances_argmin(X, centers)\n",
    "\n",
    "subplt = plt.subplot(221)\n",
    "for k, col in zip(range(clusters), colors):\n",
    "    my_members = kmeans_labels == k\n",
    "    cluster_center = centers[k]\n",
    "    subplt.plot(X[my_members, 0], X[my_members, 1], 'w',\n",
    "            markerfacecolor=col, marker='.')\n",
    "    subplt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "            markeredgecolor='k', markersize=6)\n",
    "subplt.set_title('KMeans')\n",
    "plt.text(10, 8,  'train time: %.2fs\\ninertia: %f' % (\n",
    "    t_batch, kmeans.inertia_))\n",
    "print(\"coordonnées des centres des clusters :\\n\", centers)\n",
    "#print(\"\\ntraining time : \",t_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],[1, 2], [1, 3], [2, 3]]):\n",
    "    X=X_train[:,pair]\n",
    "    # Shuffle\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.seed(13)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    # Standardize\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    # Train\n",
    "    clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    values=['sum','mean','variance','outline_length']\n",
    "    plt.xlabel(values[pair[0]])\n",
    "    plt.ylabel(values[pair[1]])\n",
    "    plt.axis(\"auto\")\n",
    "    targets=most_important_features\n",
    "    \n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired, label=targets[i])\n",
    "\n",
    "    plt.axis(\"auto\")\n",
    "\n",
    "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "\n",
    "#TO CORRECT\n",
    "#works but is in the plot so we cannot see the data\n",
    "#plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Fit regression model\n",
    "X_test= D.data['X_test']\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X_train, y)\n",
    "regr_2.fit(X_train, y)\n",
    "# Predict\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_train, y_1, color=\"cornflowerblue\",label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_train, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_train, Y_hat_train, alpha ='0.5', s = 1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h3>Cross-validation performance</h3>\n",
    "    <p>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. The average CV result and 95% confidence interval is displayed.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(M, X_train, Y_train, cv=5, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1> Step 3: Making a submission </h1> \n",
    "\n",
    "<h2> Unit testing </h2> \n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. \n",
    "<br>\n",
    "Keep the sample code simple.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!source activate python3; python $problem_dir/ingestion.py $data_dir $result_dir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "Also test the scoring program:\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_output_dir = 'scoring_output'\n",
    "!source activate python3; python $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div>\n",
    "    <h1> Preparing the submission </h1>\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = '../sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = '../sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
